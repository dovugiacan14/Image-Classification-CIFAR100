{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b1cd3a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-31T12:54:43.581978Z",
     "iopub.status.busy": "2025-05-31T12:54:43.581715Z",
     "iopub.status.idle": "2025-05-31T12:54:44.866927Z",
     "shell.execute_reply": "2025-05-31T12:54:44.866185Z"
    },
    "papermill": {
     "duration": 1.289585,
     "end_time": "2025-05-31T12:54:44.868314",
     "exception": false,
     "start_time": "2025-05-31T12:54:43.578729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Image-Classification-CIFAR100'...\r\n",
      "remote: Enumerating objects: 119, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (119/119), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (77/77), done.\u001b[K\r\n",
      "remote: Total 119 (delta 65), reused 86 (delta 35), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (119/119), 26.36 KiB | 5.27 MiB/s, done.\r\n",
      "Resolving deltas: 100% (65/65), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/dovugiacan14/Image-Classification-CIFAR100.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c7e397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T12:54:44.873486Z",
     "iopub.status.busy": "2025-05-31T12:54:44.873211Z",
     "iopub.status.idle": "2025-05-31T12:56:04.938632Z",
     "shell.execute_reply": "2025-05-31T12:56:04.937560Z"
    },
    "papermill": {
     "duration": 80.069789,
     "end_time": "2025-05-31T12:56:04.940329",
     "exception": false,
     "start_time": "2025-05-31T12:54:44.870540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_optimizer\r\n",
      "  Downloading torch_optimizer-0.3.0-py3-none-any.whl.metadata (55 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from torch_optimizer) (2.6.0+cu124)\r\n",
      "Collecting pytorch-ranger>=0.1.1 (from torch_optimizer)\r\n",
      "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl.metadata (509 bytes)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (4.13.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.5.0->torch_optimizer)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.5.0->torch_optimizer)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.5.0->torch_optimizer)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.5.0->torch_optimizer)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.5.0->torch_optimizer)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.5.0->torch_optimizer)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.5.0->torch_optimizer)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torch_optimizer) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->torch_optimizer) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->torch_optimizer) (3.0.2)\r\n",
      "Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-ranger, torch_optimizer\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-ranger-0.1.1 torch_optimizer-0.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27d548f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T12:56:04.979621Z",
     "iopub.status.busy": "2025-05-31T12:56:04.979045Z",
     "iopub.status.idle": "2025-05-31T12:56:04.986619Z",
     "shell.execute_reply": "2025-05-31T12:56:04.985944Z"
    },
    "papermill": {
     "duration": 0.028747,
     "end_time": "2025-05-31T12:56:04.987656",
     "exception": false,
     "start_time": "2025-05-31T12:56:04.958909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/Image-Classification-CIFAR100/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/Image-Classification-CIFAR100/config.py\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_optimizer import Lookahead\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "save_dir = \"checkpoints/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_workers = 16\n",
    "\n",
    "\n",
    "class CNNConfig:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 100\n",
    "    batch_size = 16\n",
    "    device = device\n",
    "    out_name = \"cnn_model\"\n",
    "    os.makedirs(out_name, exist_ok= True)\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer_fn(model):\n",
    "        return optim.Adam(model.parameters(), lr=CNNConfig.learning_rate)\n",
    "\n",
    "\n",
    "class ResNetConfig:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-4\n",
    "    num_epochs = 100\n",
    "    batch_size = 32\n",
    "    device = device\n",
    "    out_name = save_dir + \"ResNet50/resnet50_model\"\n",
    "    num_workers = num_workers\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer_fn(model):\n",
    "        return optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=ResNetConfig.learning_rate,\n",
    "            weight_decay=ResNetConfig.weight_decay,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def scheduler_fn(optimizer):\n",
    "        return optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=ResNetConfig.num_epochs\n",
    "        )\n",
    "\n",
    "\n",
    "class VGGConfig:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch_size = 32\n",
    "    num_epochs = 2\n",
    "    learning_rate = 1e-4\n",
    "    device = device\n",
    "    out_name = \"vgg16_model\"\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer_fn(model):\n",
    "        return optim.Adam(model.parameters(), lr=VGGConfig.learning_rate)\n",
    "\n",
    "\n",
    "class DenseNetConfig:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-4\n",
    "    num_epochs = 100\n",
    "    batch_size = 32\n",
    "    device = device\n",
    "    out_name = save_dir + \"DenseNet/densenet121_model\"\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer_fn(model):\n",
    "        return optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=DenseNetConfig.learning_rate,\n",
    "            weight_decay=DenseNetConfig.weight_decay,\n",
    "        )\n",
    "\n",
    "\n",
    "class EfficientConfig:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch_size = 32\n",
    "    num_epochs = 2\n",
    "    learning_rate = 1e-4\n",
    "    device = device\n",
    "    out_name = \"efficientnetb0_finetune_model\"\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer_fn(model):\n",
    "        return optim.Adam(model.parameters(), lr=EfficientConfig.learning_rate)\n",
    "\n",
    "\n",
    "class ConvNeXtConfig:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    learning_rate = 3e-4\n",
    "    num_epochs = 100\n",
    "    batch_size = 32\n",
    "    device = device\n",
    "    out_name = save_dir + \"ConvNeXt/convnext_tiny_model\"\n",
    "    grad_clip = 1.0  # gradient clipping value\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer_fn(model):\n",
    "        base_opt = optim.AdamW(\n",
    "            model.parameters(), lr=ConvNeXtConfig.learning_rate, weight_decay=1e-4\n",
    "        )\n",
    "        return Lookahead(base_opt)\n",
    "\n",
    "\n",
    "class ViTConfig:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    num_epochs = 2\n",
    "    batch_size = 32\n",
    "    learning_rate = 2e-5\n",
    "    weight_decay = 0.01\n",
    "    T_max = 10\n",
    "    device = device\n",
    "    out_name = \"ViT_finetune_model\"\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer_fn(model):\n",
    "        return optim.AdamW(model.parameters(), lr=ViTConfig.learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    def scheduler():\n",
    "        return optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer=ViTConfig.optimizer_fn, T_max=ViTConfig.T_max\n",
    "        )\n",
    "\n",
    "\n",
    "class SwinConfig:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate = 2e-5\n",
    "    weight_decay = 0.01\n",
    "    num_epochs = 100\n",
    "    batch_size = 32\n",
    "    device = device\n",
    "    out_name = save_dir + \"SwinTransformer/swin_transformer_tiny_model\"\n",
    "    model_name = \"microsoft/swin-tiny-patch4-window7-224\"\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer_fn(model):\n",
    "        return optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=SwinConfig.learning_rate,\n",
    "            weight_decay=SwinConfig.weight_decay,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad72edc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T12:56:05.043684Z",
     "iopub.status.busy": "2025-05-31T12:56:05.042886Z",
     "iopub.status.idle": "2025-05-31T16:49:14.422084Z",
     "shell.execute_reply": "2025-05-31T16:49:14.421332Z"
    },
    "papermill": {
     "duration": 13989.411831,
     "end_time": "2025-05-31T16:49:14.423682",
     "exception": false,
     "start_time": "2025-05-31T12:56:05.011851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-31 12:56:20.012760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1748696180.199267      63 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1748696180.251763      63 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "100%|████████████████████████████████████████| 169M/169M [00:15<00:00, 11.1MB/s]\r\n",
      "----------------------------------------------------------------\r\n",
      "        Layer (type)               Output Shape         Param #\r\n",
      "================================================================\r\n",
      "            Conv2d-1         [-1, 32, 224, 224]             896\r\n",
      "       BatchNorm2d-2         [-1, 32, 224, 224]              64\r\n",
      "              ReLU-3         [-1, 32, 224, 224]               0\r\n",
      "         MaxPool2d-4         [-1, 32, 112, 112]               0\r\n",
      "            Conv2d-5         [-1, 64, 112, 112]          18,496\r\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\r\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\r\n",
      "         MaxPool2d-8           [-1, 64, 56, 56]               0\r\n",
      "            Conv2d-9          [-1, 128, 56, 56]          73,856\r\n",
      "      BatchNorm2d-10          [-1, 128, 56, 56]             256\r\n",
      "             ReLU-11          [-1, 128, 56, 56]               0\r\n",
      "        MaxPool2d-12          [-1, 128, 28, 28]               0\r\n",
      "AdaptiveAvgPool2d-13            [-1, 128, 1, 1]               0\r\n",
      "          Flatten-14                  [-1, 128]               0\r\n",
      "           Linear-15                  [-1, 256]          33,024\r\n",
      "             ReLU-16                  [-1, 256]               0\r\n",
      "          Dropout-17                  [-1, 256]               0\r\n",
      "           Linear-18                  [-1, 100]          25,700\r\n",
      "================================================================\r\n",
      "Total params: 152,420\r\n",
      "Trainable params: 152,420\r\n",
      "Non-trainable params: 0\r\n",
      "----------------------------------------------------------------\r\n",
      "Input size (MB): 0.57\r\n",
      "Forward/backward pass size (MB): 69.68\r\n",
      "Params size (MB): 0.58\r\n",
      "Estimated Total Size (MB): 70.84\r\n",
      "----------------------------------------------------------------\r\n",
      "Epoch [1/100], Loss: 4.0180, Train Acc: 8.00%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [2/100], Loss: 3.7474, Train Acc: 11.52%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [3/100], Loss: 3.6197, Train Acc: 13.72%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [4/100], Loss: 3.5310, Train Acc: 15.30%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [5/100], Loss: 3.4477, Train Acc: 16.71%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [6/100], Loss: 3.3433, Train Acc: 18.72%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [7/100], Loss: 3.2329, Train Acc: 20.52%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [8/100], Loss: 3.1504, Train Acc: 21.96%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [9/100], Loss: 3.0847, Train Acc: 23.28%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [10/100], Loss: 3.0182, Train Acc: 24.20%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [11/100], Loss: 2.9637, Train Acc: 25.21%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [12/100], Loss: 2.9206, Train Acc: 26.29%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [13/100], Loss: 2.8745, Train Acc: 27.21%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [14/100], Loss: 2.8302, Train Acc: 27.97%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [15/100], Loss: 2.7964, Train Acc: 28.86%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [16/100], Loss: 2.7631, Train Acc: 29.34%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [17/100], Loss: 2.7317, Train Acc: 30.14%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [18/100], Loss: 2.6988, Train Acc: 30.53%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [19/100], Loss: 2.6714, Train Acc: 31.12%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [20/100], Loss: 2.6487, Train Acc: 31.44%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [21/100], Loss: 2.6177, Train Acc: 32.33%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [22/100], Loss: 2.6060, Train Acc: 32.51%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [23/100], Loss: 2.5840, Train Acc: 33.10%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [24/100], Loss: 2.5535, Train Acc: 33.63%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [25/100], Loss: 2.5395, Train Acc: 33.84%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [26/100], Loss: 2.5261, Train Acc: 34.01%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [27/100], Loss: 2.5073, Train Acc: 34.41%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [28/100], Loss: 2.4831, Train Acc: 34.86%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [29/100], Loss: 2.4716, Train Acc: 35.17%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [30/100], Loss: 2.4534, Train Acc: 35.73%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [31/100], Loss: 2.4419, Train Acc: 35.86%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [32/100], Loss: 2.4208, Train Acc: 36.28%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [33/100], Loss: 2.4088, Train Acc: 36.45%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [34/100], Loss: 2.3965, Train Acc: 36.87%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [35/100], Loss: 2.3808, Train Acc: 36.99%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [36/100], Loss: 2.3711, Train Acc: 37.34%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [37/100], Loss: 2.3534, Train Acc: 37.82%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [38/100], Loss: 2.3389, Train Acc: 38.17%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [39/100], Loss: 2.3357, Train Acc: 37.97%\r\n",
      "Epoch [40/100], Loss: 2.3271, Train Acc: 38.62%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [41/100], Loss: 2.3132, Train Acc: 38.54%\r\n",
      "Epoch [42/100], Loss: 2.2998, Train Acc: 38.97%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [43/100], Loss: 2.2830, Train Acc: 39.32%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [44/100], Loss: 2.2870, Train Acc: 39.10%\r\n",
      "Epoch [45/100], Loss: 2.2683, Train Acc: 39.84%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [46/100], Loss: 2.2562, Train Acc: 39.88%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [47/100], Loss: 2.2498, Train Acc: 40.07%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [48/100], Loss: 2.2411, Train Acc: 40.08%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [49/100], Loss: 2.2329, Train Acc: 40.34%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [50/100], Loss: 2.2231, Train Acc: 40.40%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [51/100], Loss: 2.2119, Train Acc: 40.56%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [52/100], Loss: 2.2049, Train Acc: 40.94%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [53/100], Loss: 2.1920, Train Acc: 41.14%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [54/100], Loss: 2.1830, Train Acc: 41.51%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [55/100], Loss: 2.1804, Train Acc: 41.52%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [56/100], Loss: 2.1669, Train Acc: 41.52%\r\n",
      "Epoch [57/100], Loss: 2.1595, Train Acc: 41.75%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [58/100], Loss: 2.1545, Train Acc: 42.08%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [59/100], Loss: 2.1448, Train Acc: 42.33%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [60/100], Loss: 2.1350, Train Acc: 42.37%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [61/100], Loss: 2.1364, Train Acc: 42.49%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [62/100], Loss: 2.1227, Train Acc: 42.71%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [63/100], Loss: 2.1160, Train Acc: 42.80%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [64/100], Loss: 2.1072, Train Acc: 43.02%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [65/100], Loss: 2.1014, Train Acc: 43.18%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [66/100], Loss: 2.0882, Train Acc: 43.38%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [67/100], Loss: 2.0841, Train Acc: 43.56%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [68/100], Loss: 2.0802, Train Acc: 43.69%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [69/100], Loss: 2.0684, Train Acc: 43.90%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [70/100], Loss: 2.0683, Train Acc: 43.71%\r\n",
      "Epoch [71/100], Loss: 2.0646, Train Acc: 44.16%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [72/100], Loss: 2.0624, Train Acc: 43.88%\r\n",
      "Epoch [73/100], Loss: 2.0522, Train Acc: 44.68%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [74/100], Loss: 2.0449, Train Acc: 44.62%\r\n",
      "Epoch [75/100], Loss: 2.0367, Train Acc: 44.97%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [76/100], Loss: 2.0295, Train Acc: 44.67%\r\n",
      "Epoch [77/100], Loss: 2.0245, Train Acc: 44.93%\r\n",
      "Epoch [78/100], Loss: 2.0269, Train Acc: 44.73%\r\n",
      "Epoch [79/100], Loss: 2.0178, Train Acc: 44.83%\r\n",
      "Epoch [80/100], Loss: 2.0063, Train Acc: 45.11%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [81/100], Loss: 2.0018, Train Acc: 45.15%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [82/100], Loss: 1.9961, Train Acc: 45.38%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [83/100], Loss: 1.9967, Train Acc: 45.67%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [84/100], Loss: 1.9940, Train Acc: 45.70%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [85/100], Loss: 1.9823, Train Acc: 45.86%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [86/100], Loss: 1.9867, Train Acc: 45.81%\r\n",
      "Epoch [87/100], Loss: 1.9811, Train Acc: 45.81%\r\n",
      "Epoch [88/100], Loss: 1.9685, Train Acc: 46.25%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [89/100], Loss: 1.9550, Train Acc: 46.53%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [90/100], Loss: 1.9627, Train Acc: 46.35%\r\n",
      "Epoch [91/100], Loss: 1.9531, Train Acc: 46.62%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [92/100], Loss: 1.9518, Train Acc: 46.31%\r\n",
      "Epoch [93/100], Loss: 1.9479, Train Acc: 46.40%\r\n",
      "Epoch [94/100], Loss: 1.9448, Train Acc: 46.46%\r\n",
      "Epoch [95/100], Loss: 1.9352, Train Acc: 46.68%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [96/100], Loss: 1.9364, Train Acc: 46.96%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [97/100], Loss: 1.9328, Train Acc: 47.15%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [98/100], Loss: 1.9240, Train Acc: 47.20%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [99/100], Loss: 1.9196, Train Acc: 47.29%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Epoch [100/100], Loss: 1.9137, Train Acc: 47.32%\r\n",
      "New best model saved to cnn_model_best.pt.\r\n",
      "Last model saved to cnn_model_last.pt.\r\n",
      "Time for training: 13922.278469324112\r\n",
      "Test Accuracy: 46.43% | Avg Loss: 2.0111\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/working/Image-Classification-CIFAR100/main.py --option 1"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14075.434147,
   "end_time": "2025-05-31T16:49:14.779741",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-31T12:54:39.345594",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
